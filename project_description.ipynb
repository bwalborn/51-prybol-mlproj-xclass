{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbiK6hgsKMNKfSlLzAHkLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanderbilt-ml/51-prybol-mlproj-xclass/blob/data_cleaning/project_description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed Project\n",
        "\n",
        "##Background\n",
        "I work as a data science executive for a healthcare technology company that offers predictive analytics, data augumentation, and warehousing for health insurance companies, provider networks, health systems, and large employer groups. As part of our offerings we have developed a robust set of validations that allow us to standardize and normalize data at massive scales. Most of these validations however, are rules and/or statistics based and their development requires significant effort from subject matter experts. With the long term goal of scaling beyond the limits of constrained resoures (SME effort) we have been seeking machine learning drive approachs that would allow us to algorithmically identify potential anomalies without a priori knowledge of what those anomalies may be. One potential validation would be to predict which diagnosis codes should appear on a medical claim based on the billed procedure codes and flag anomalous claims where the diagnosis codes do not match expectations. \n",
        "\n",
        "\n",
        "## Project Description\n",
        "Predicting diagnosis codes from procedure codes appears to be a straightfoward proposition, but the processs is deceivingy complex. With the switch to ICD-10, there are now more than 70,000 unique procedure codes or \"tokens\". This number grows even larger with the inclusion of the Current Procedural Terminology (CPT) code set (10,471 unqiue CPT codes). For reference, this combined vocabulary is nearly three times larger than the vocabularly used in Google's seminal natural language processing paper on BERT (Bidirectional Encoder Representations from Transformers). Each healthcare encounter can result in any number of unique procedure codes being billed. While the number of codes billed in a single claim or encounter is technically unlimited, a typical range is anywhere from 1 to 25. Given the large vocabulary and the variable length of codes billed to a single encounter, one common way to handle these complexities is by treating medical codes as \"words\" in a \"sentence\" or \"document\". \n",
        "\n",
        "Addtionally, the model target, in this case the complete set of ICD diagnosis codes, contains more than 69,000 unique values. While some of these tokens are are quite common, others are exceedingly rare. Any loss function used during model training need to take into account the relative prevalences of these codes. It stands to reason that the more rare the code in the target set, the more imporant it may be to any anomaly detection engine. \n",
        "\n",
        "Extreme multi-label classification (XMC) is the problem of finding the relevant labels for an input, from a very large universe of possible labels. XMC is a natural fit for this project given the scope of the target. As a result, this project will borrow heavily from the fields of natural language processing and XMC.  \n",
        "\n",
        "To date, no administrative claims data has been made publically available for research purposes. For this project I will leverage my existing access to the [MIMIC-IV (Medical Information Mart for Intensive Care)](https://mimic.mit.edu) research database that contains the data from over 500,000 intensive care stays. This database has been augmented to include the billed procedure and diagnosis codes. While the total subset of unique codes will be limited by the types of nature of the dataset (limited to ICU stays), the overall scope should be representitive of the larger scale problem. \n",
        "\n",
        "# Performance Metrics\n",
        "Peformance will be measured using metrics that have been widely adopted for XML and ranking tasks. Precision at $k$ (p$@k$) is one such metric that counts the fraction of correct predictions in the top $k$ scoring labels in $\\hat{y}$, and has been widely utilized. The ranking measure Normalized (Discounted) Cumlative Gain at $k$ (nDCG$@k$) as another evaluation metric. The p$@k$ and nDCG$@k$ metrics are defined for a predicted score vector $\\hat{\\mathbf y} \\in {\\mathbb{R}}^{L}$ and ground truth label vector $\\mathbf y \\in \\left\\lbrace 0, 1 \\right\\rbrace^L$ as: \n",
        "\n",
        "\\begin{align}\n",
        "        \\text{P}@k := \\frac{1}{k} \\sum_{l\\in \\text{rank}_k (\\hat{\\mathbf y})} \\mathbf y_l\\\\[1em]\n",
        "        \\text{DCG}@k := \\sum_{l\\in {\\text{rank}}_k (\\hat{\\mathbf y})} \\frac{\\mathbf y_l}{\\log(l+1)}\\\\[1em]\n",
        "        \\text{nDCG}@k := \\frac{{\\text{DCG}}@k}{\\sum_{l=1}^{\\min(k, \\|\\mathbf y\\|_0)} \\frac{1}{\\log(l+1)}},\\\\[1em]\n",
        "    \\end{align}\n",
        "\n",
        "where, $\\text{rank}_k(\\mathbf y)$ returns the $k$ largest indices of $\\mathbf{y}$ ranked in descending order.\n",
        "\n",
        "For datasets that contain excessively popular labels (often referred to as \"head\" labels) such as diagnosis codes, high p$@k$ may be achieved by simply predicting head labels repeatedly irrespective of their relevance to the data point. To check for such trivial behavior, it is recommended that XC methods also be evaluated with respect to propensity-scored counterparts of the p$@k$ and nDCG$@k$ metrics (PSP$@k$ and PSnDCG$@k$) described below.\n",
        "\n",
        "\\begin{align}\n",
        "        \\text{PSP}@k := \\frac{1}{k} \\sum_{l\\in \\text{rank}_k (\\hat{\\mathbf y})} \\frac{\\mathbf y_l}{p_l}\\\\[1em]\n",
        "        \\text{PSDCG}@k := \\sum_{l\\in {\\text{rank}}_k (\\hat{\\mathbf y})} \\frac{\\mathbf y_l}{p_l\\log(l+1)}\\\\[1em]\n",
        "        \\text{PSnDCG}@k := \\frac{{\\text{PSDCG}}@k}{\\sum_{l=1}^{k} \\frac{1}{\\log(l+1)}},\\\\[1em]\n",
        "    \\end{align}\n",
        "\n",
        "where $p_l$ is the propensity score for label $l$ which helps in making metrics unbiased with respect to missing labels. Propensity-scored metrics place specific emphasis on performing well on tail labels and give reduced rewards for predicting popular or head labels. For this study we will use metrics$@k$ in $\\{1,3,5\\}$.\n",
        "\n",
        "Given that as of the time of writing, no relevant papers on this topic exist, the overarching purpose of this project will be to estabish a benchmark from which future work can be compared against. "
      ],
      "metadata": {
        "id": "TZfYKV6mxREL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion and Cleaning"
      ],
      "metadata": {
        "id": "Zp0-w3_KfXCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -r -N -c -np --user kprybol --ask-password https://physionet.org/files/mimiciv/1.0/core/patients.csv.gz\n",
        "!wget -r -N -c -np --user kprybol --ask-password https://physionet.org/files/mimiciv/1.0/core/admissions.csv.gz\n",
        "!wget -r -N -c -np --user kprybol --ask-password https://physionet.org/files/mimiciv/1.0/hosp/procedures_icd.csv.gz\n",
        "!wget -r -N -c -np --user kprybol --ask-password https://physionet.org/files/mimiciv/1.0/hosp/diagnoses_icd.csv.gz\n",
        "!wget -r -N -c -np --user kprybol --ask-password https://physionet.org/files/mimiciv/1.0/hosp/drgcodes.csv.gz"
      ],
      "metadata": {
        "id": "U7b_fqOWeLR4",
        "outputId": "fd88daeb-5fc0-454f-a6a1-0ea323ee0fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password for user ‘kprybol’: \n",
            "--2022-05-20 20:12:28--  https://physionet.org/files/mimiciv/1.0/core/patients.csv.gz\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"PhysioNet\", charset=\"UTF-8\"\n",
            "Reusing existing connection to physionet.org:443.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘physionet.org/files/mimiciv/1.0/core/patients.csv.gz’ not modified on server. Omitting download.\n",
            "\n",
            "Password for user ‘kprybol’: \n",
            "--2022-05-20 20:12:34--  https://physionet.org/files/mimiciv/1.0/core/admissions.csv.gz\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"PhysioNet\", charset=\"UTF-8\"\n",
            "Reusing existing connection to physionet.org:443.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘physionet.org/files/mimiciv/1.0/core/admissions.csv.gz’ not modified on server. Omitting download.\n",
            "\n",
            "Password for user ‘kprybol’: \n",
            "--2022-05-20 20:12:40--  https://physionet.org/files/mimiciv/1.0/hosp/procedures_icd.csv.gz\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"PhysioNet\", charset=\"UTF-8\"\n",
            "Reusing existing connection to physionet.org:443.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘physionet.org/files/mimiciv/1.0/hosp/procedures_icd.csv.gz’ not modified on server. Omitting download.\n",
            "\n",
            "Password for user ‘kprybol’: \n",
            "--2022-05-20 20:12:46--  https://physionet.org/files/mimiciv/1.0/hosp/diagnoses_icd.csv.gz\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"PhysioNet\", charset=\"UTF-8\"\n",
            "Reusing existing connection to physionet.org:443.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘physionet.org/files/mimiciv/1.0/hosp/diagnoses_icd.csv.gz’ not modified on server. Omitting download.\n",
            "\n",
            "Password for user ‘kprybol’: \n",
            "--2022-05-20 20:12:52--  https://physionet.org/files/mimiciv/1.0/hosp/drgcodes.csv.gz\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"PhysioNet\", charset=\"UTF-8\"\n",
            "Reusing existing connection to physionet.org:443.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘physionet.org/files/mimiciv/1.0/hosp/drgcodes.csv.gz’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "v2UfAsmDeQR2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pat_df = pd.read_csv('physionet.org/files/mimiciv/1.0/core/patients.csv.gz')\n",
        "admit_df = pd.read_csv('physionet.org/files/mimiciv/1.0/core/admissions.csv.gz')\n",
        "proc_df = pd.read_csv('physionet.org/files/mimiciv/1.0/hosp/procedures_icd.csv.gz')\n",
        "diag_df = pd.read_csv('physionet.org/files/mimiciv/1.0/hosp/diagnoses_icd.csv.gz')\n",
        "drg_df = pd.read_csv('physionet.org/files/mimiciv/1.0/hosp/drgcodes.csv.gz')"
      ],
      "metadata": {
        "id": "Q5G0caNMfwGN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc_gem = pd.read_csv('https://data.nber.org/gem/icd9toicd10pcsgem.csv')\n",
        "diag_gem = pd.read_csv('https://data.nber.org/gem/icd9toicd10cmgem.csv')"
      ],
      "metadata": {
        "id": "T764HAIIiTjX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_diag_icd10(df, gem):\n",
        "  dx_comb = df.merge(gem, how='left', left_on='icd_code', right_on='icd9cm')\n",
        "  dx_comb['icd_10_recode'] = dx_comb['icd_code'][dx_comb['icd_version'] == 10]\n",
        "  dx_comb['icd_10_recode'] = dx_comb['icd10cm'][dx_comb['icd_version'] == 9]\n",
        "  dx_comb = dx_comb[['subject_id', 'hadm_id', 'seq_num', 'icd_10_recode']]\n",
        "  return dx_comb"
      ],
      "metadata": {
        "id": "i3IVi-nogajT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_proc_icd10(df, gem):\n",
        "  df.icd_code = df.icd_code.astype(str)\n",
        "  gem.icd9cm = gem.icd9cm.astype(str)\n",
        "  dx_comb = df.merge(gem, how='left', left_on='icd_code', right_on='icd9cm')\n",
        "  dx_comb['icd_10_recode'] = dx_comb['icd_code'][dx_comb['icd_version'] == 10]\n",
        "  dx_comb['icd_10_recode'] = dx_comb['icd10cm'][dx_comb['icd_version'] == 9]\n",
        "  dx_comb = dx_comb[['subject_id', 'hadm_id', 'seq_num', 'icd_10_recode']]\n",
        "  return dx_comb"
      ],
      "metadata": {
        "id": "wIzOhONuY59j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diag10_df = convert_diag_icd10(diag_df, diag_gem)\n",
        "proc10_df = convert_proc_icd10(proc_df, proc_gem)"
      ],
      "metadata": {
        "id": "OnYjMYeHgcQL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pat_df = pat_df.merge(admit_df[['subject_id', 'hadm_id', 'admittime']], how='inner', on='subject_id')"
      ],
      "metadata": {
        "id": "9vcQvmnVYv0_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "def convert_anchor_year(x):\n",
        "  return dt.datetime.combine(dt.date(x, 1, 1), dt.time(0, 0))\n",
        "\n",
        "\n",
        "pat_df['anchor_dt'] = pat_df['anchor_year'].apply(convert_anchor_year)\n",
        "pat_df['admittime'] = pd.to_datetime(pat_df['admittime'])"
      ],
      "metadata": {
        "id": "pQz70R7ublnM"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pat_df['age'] = pd.DatetimeIndex(pat_df['admittime']).year - pd.DatetimeIndex(pat_df['anchor_dt']).year + pat_df['anchor_age']"
      ],
      "metadata": {
        "id": "04ynY_tZGxdY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pat_df.head()"
      ],
      "metadata": {
        "id": "B4zaa7DnHpQ1",
        "outputId": "debe9f0d-61dc-47db-ca5e-12f03a788df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   subject_id gender  anchor_age  anchor_year anchor_year_group  dod  \\\n",
              "0    10002723      F           0         2128       2017 - 2019  NaN   \n",
              "1    10002723      F           0         2128       2017 - 2019  NaN   \n",
              "2    10003939      M           0         2184       2008 - 2010  NaN   \n",
              "3    10004222      M           0         2161       2014 - 2016  NaN   \n",
              "4    10005325      F           0         2154       2011 - 2013  NaN   \n",
              "\n",
              "    hadm_id           admittime  anchor_dt  age  \n",
              "0  26724970 2128-06-10 15:29:00 2128-01-01    0  \n",
              "1  20429365 2128-06-13 14:15:00 2128-01-01    0  \n",
              "2  22561709 2184-06-26 17:48:00 2184-01-01    0  \n",
              "3  22106441 2161-05-29 21:09:00 2161-01-01    0  \n",
              "4  20047480 2154-12-15 14:10:00 2154-01-01    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16395031-f84c-4767-80f1-65390e11364d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>anchor_age</th>\n",
              "      <th>anchor_year</th>\n",
              "      <th>anchor_year_group</th>\n",
              "      <th>dod</th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>admittime</th>\n",
              "      <th>anchor_dt</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10002723</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>2128</td>\n",
              "      <td>2017 - 2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26724970</td>\n",
              "      <td>2128-06-10 15:29:00</td>\n",
              "      <td>2128-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10002723</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>2128</td>\n",
              "      <td>2017 - 2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20429365</td>\n",
              "      <td>2128-06-13 14:15:00</td>\n",
              "      <td>2128-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10003939</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>2184</td>\n",
              "      <td>2008 - 2010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22561709</td>\n",
              "      <td>2184-06-26 17:48:00</td>\n",
              "      <td>2184-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10004222</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>2161</td>\n",
              "      <td>2014 - 2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22106441</td>\n",
              "      <td>2161-05-29 21:09:00</td>\n",
              "      <td>2161-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10005325</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>2154</td>\n",
              "      <td>2011 - 2013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20047480</td>\n",
              "      <td>2154-12-15 14:10:00</td>\n",
              "      <td>2154-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16395031-f84c-4767-80f1-65390e11364d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16395031-f84c-4767-80f1-65390e11364d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16395031-f84c-4767-80f1-65390e11364d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1lh6s4BjstBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}